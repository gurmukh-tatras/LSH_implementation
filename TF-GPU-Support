run 'ubuntu-drivers devices' in terminal
see which version of nvidia drivers is recommended
sudo apt install -y nvidia-driver-440 (recommended driver)
reboot
type nvidia-smi, it should list available GPU memory, and other info

--------------------------------------------------------------------
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | \
  sudo apt-key add -

distribution=$(. /etc/os-release;echo $ID$VERSION_ID)

curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update

sudo apt-get install -y nvidia-docker2
sudo pkill -SIGHUP dockerd
----------------------------------------------------------------------------
docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi
# the output should be similar to what you get by running nvidia-smi command in terminal .
 the only thing you need from your OS is the nvidia driver
, no more trouble with cuda/cudnn/gcc version
-----------------------------------------------------------
#benchmarking
docker run --runtime=nvidia --rm -ti -v "${PWD}:/app" tensorflow/tensorflow:latest-gpu-jupyter python /app/benchmark.py cpu 10000
docker run --runtime=nvidia --rm -ti -v "${PWD}:/app" tensorflow/tensorflow:latest-gpu-jupyter python /app/benchmark.py gpu 10000

docker run --runtime=nvidia --rm -ti -v "${PWD}:/app" tensorflow/tensorflow:latest-gpu-jupyter
or bush docker-build.sh
docker exec -it DOCKER_CONTAINER_ID /bin/bash










